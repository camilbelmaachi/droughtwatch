{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes you have already followed the steps in `README.md`. If not, do that first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import argparse\n",
    "import math\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6e73bfd1de6c>:8: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n"
     ]
    }
   ],
   "source": [
    "dirlist = lambda di: [os.path.join(di, file) for file in os.listdir(di) if 'part-' in file]\n",
    "training_files = dirlist('data/val/')\n",
    "\n",
    "def parse_visual(data):\n",
    "    dataset = tf.data.TFRecordDataset(data)\n",
    "    # pattern for one part file\n",
    "    # dataset = tf.data.TFRecordDataset('part-r-00099')\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "    features = {\n",
    "        'B2': tf.FixedLenFeature([], tf.string),\n",
    "        'B3': tf.FixedLenFeature([], tf.string),\n",
    "        'B4': tf.FixedLenFeature([], tf.string),\n",
    "        'label': tf.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    parsed_examples = [tf.parse_single_example(data, features) for data in iterator]\n",
    "    return parsed_examples\n",
    "\n",
    "parsed_examples = parse_visual(training_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_from_example(parsed_example, intensify=True):\n",
    "    rgbArray = np.zeros((65,65,3), 'uint8')\n",
    "    for i, band in enumerate(['B4', 'B3', 'B2']):\n",
    "        band_data = np.frombuffer(parsed_example[band].numpy(), dtype=np.uint8)\n",
    "        band_data = band_data.reshape(65, 65)\n",
    "        if intensify:\n",
    "            band_data = band_data/np.max(band_data)*255\n",
    "        else:\n",
    "            band_data = band_data*255\n",
    "        rgbArray[..., i] = band_data\n",
    "        \n",
    "    label = tf.cast(parsed_example['label'], tf.int32).numpy()\n",
    "        \n",
    "    return rgbArray, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[243 244 243]\n",
      "  [243 243 243]\n",
      "  [243 244 243]\n",
      "  ...\n",
      "  [244 244 245]\n",
      "  [244 244 245]\n",
      "  [244 244 245]]\n",
      "\n",
      " [[243 244 245]\n",
      "  [243 244 243]\n",
      "  [243 244 243]\n",
      "  ...\n",
      "  [244 244 245]\n",
      "  [244 244 245]\n",
      "  [244 246 246]]\n",
      "\n",
      " [[244 244 245]\n",
      "  [244 244 245]\n",
      "  [244 244 245]\n",
      "  ...\n",
      "  [244 246 245]\n",
      "  [244 246 246]\n",
      "  [244 246 246]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[252 253 252]\n",
      "  [252 253 252]\n",
      "  [252 253 252]\n",
      "  ...\n",
      "  [253 253 252]\n",
      "  [252 252 252]\n",
      "  [252 252 252]]\n",
      "\n",
      " [[253 253 252]\n",
      "  [252 253 252]\n",
      "  [252 253 252]\n",
      "  ...\n",
      "  [252 253 252]\n",
      "  [252 253 252]\n",
      "  [252 252 252]]\n",
      "\n",
      " [[252 253 252]\n",
      "  [252 253 252]\n",
      "  [253 253 252]\n",
      "  ...\n",
      "  [252 252 252]\n",
      "  [252 253 252]\n",
      "  [252 252 252]]]\n",
      "2.8400864917552724\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYn0lEQVR4nO2dX6xlVX3Hv9/Ln2rVCDi3kwnDdGgkGh7qQG4QIxqEYqg1wgMhGtNMm0nmxTaYmgi0SROTPuiLykPTZCLUeaACRe0QYlQ6QmiTBrkUVGBERooyk4G500C0fdDC/fXh7Mvss89e6/7O2mvvs++s7+fm5J6z99pr/faf316/3/r3o5lBCHHms7RoAYQQwyBlF6IQpOxCFIKUXYhCkLILUQhSdiEKoZOyk7ye5HMkj5K8LZdQQoj8MLWfneRZAH4G4DoAxwA8DuBTZvZsPvGEELk4u8OxVwA4amYvAADJewDcACCo7Nu2bbNdu3Z1KFIIEeOXv/wlTp06xbZ9XZT9QgAv1X4fA/D+2AG7du3Co//26ORH06Coi+c1NlpPKScpXs56x+PHynr75hz3sUnovsbKchO+J70/TjXqp5Kz3A996Krgvt6fRpL7Sa6SXD116lTfxQkhAnSp2Y8DuKj2e2e1bQozOwDgAABcfvnl9ub7hYGaAhhpje2DZ1RtfhoLnVfsXuW+j9H8whZVZzFmTr2W47r50jXMErdMETWZYmnzHLs8mY8DuITkxSTPBfBJAA90yE8I0SPJNbuZvU7yLwB8D8BZAO4ys2eySSaEyEoXMx5m9h0A38kkixCiRzopewqnPYuwB+FvxI05NPN7KFlczNwuu9tny1xug1gTSxJ1eSN5x1qtp/clXADnIUuxJ6PmK8cvUezpijzxQRnnf1rPzNYkIcQMUnYhCmFwM96D3+BJe1dlHouRlPu0FRsz4xLNv84jUxrplkLdSI3jp7qinLLPpDu9b2pPw06e2pf0KEyX27XmSz1+fSCTXDW7EIUgZReiEEZpxsdaavO3mPc3XK/5Jg231obNydQW3q4jwOOmpa91Ol6TxFqx2/NYz1w1ZfbMZnF2Kw1V46pmF6IQpOxCFIKUXYhCGN5nD3bHBLpzlrwTprv73n2/+UL5x8rNIlNC713/c58jZY1Apt7zCz26Xefsx5pT5sxKCLFFkbILUQiDm/Ght0u4qyetC6h383d0xKaJxA7zukV9LaTUAp2ye0WaSpdb9sS1t1Ie946oZheiEKTsQhTCaEbQ9frW8ZpG2UPV+wrOMdVlthG3Pdd4fgym8+aXxwptl2Mm79qG6K1j69dMdM/RIr9yoppdiEKQsgtRCFJ2IQphND57kCG7VBKzYE2Q3B1U3jwGTVerImbShZZvT1zDLvd5jRFGfoVpby0Jta0AqtmFKAYpuxCFMKwZT5y2UnL02SSa7l1NvtnOEbZ8ayH7qzWWYcBuzrL6diThUqCALVGtJPgd3uuZeyluLSUthAixqbKTvIvkSZJP17ZdQPIhks9X/8/vV0whRFc8NfvXAVzf2HYbgMNmdgmAw9VvIcSI2dRnN7NHSe5ubL4BwNXV94MAHgFw6+bF1Zz2ZMe5fTjhXNmFp96F09X2uctK9IHz+FaBXBqbu0aXmr1k80sfu+y5CQd2bsrhbA9JFdZ7XOgG9RftaobtZnai+v4ygO2hhCT3k1wluXpqbS2xOCFEVzq/RM3MEBm9b2YHzGzFzFa2LS93LU4IkUhq19srJHeY2QmSOwCc9BxU73lLZwSz+2P2XzSPpZZvi2VRIY9y55GjLL9lPb/ES5FDoq5U8Lj5+/JSr/MDAPZW3/cCOJSYjxBiIDxdb98A8B8A3kPyGMl9AL4I4DqSzwP4o+q3EGLEeFrjPxXYdW1SiRuvl+wjihxlzr+zlixiq8f2efYMudxb6sjFUKtMH15VyvmnBLSdJ48aud0O7zjIrn02Y3EdhRA9I2UXohCk7EIUwvCLV2w4IcndVzlo7wKLNyPEfPHMArv94ISlKlMX+WC7I524Wn10scyUdoD6ac3K4F1D31mYt/3Cuwx/hJxPlmp2IQpByi5EISwgiqtne8y49k7J8ByTkmoTsnRFzb/evDXswthaZGl0XwM/5zHz5eddQ98ZWjUYMstVbHyfN2hxAqrZhSgEKbsQhbCAKK6T94vfOPeNG/KmS8Zpa8aWBe5zEJrbbI9P4i4Kr7nvtcdzDE5kI4KtTcWuitjxDhNfNbsQhSBlF6IQpOxCFMLCwj+lrhORlK7nWWVef3mUIYpCvZxe377rWmpnEKn3N9bOE+6ha6RzFK6aXYhCkLILUQjjieKaMqLIH+LVVVZ2MzvVxPXOzsn8ql6qLZQ2U2worJM7826HdyK3C5F7EKdbPmeYsQQRhBBnEFJ2IQpheDP+zWZD7xzjcOtkfNmxAdu+vcvY1b5PjfibOT5DxBGHDE054o3xKbbrSOi1Sqvfx3BMmVjknPXYGobrcz4LkcdeNbsQhSBlF6IQpOxCFMLCut6aPnXKoLaFdZU5M/GGGsoRCbWJd0m/7iMUw3vSI8Sut3xrO6697Nnr2Z6Lf81Bb3zXlD0N/32eA1uSxXTCExHmIpIPk3yW5DMkb6m2X0DyIZLPV//P94klhFgEnvfG6wA+Z2aXArgSwGdIXgrgNgCHzewSAIer30KIkeIJ/3QCwInq+69JHgFwIYAbAFxdJTsI4BEAt26WX8ryAEHc1m6qWdxuDA8Z/mdMeXZhHnnWO17r2WPacwmZ9xMZ6umGu5ox2X2uWViT5joLkrsBXAbgMQDbqxcBALwMYPs8eQkhhsWt7CTfDuCbAD5rZr+q7zMzQ2CMC8n9JFdJrp46daqTsEKIdFzKTvIcTBT9bjP7VrX5FZI7qv07AJxsO9bMDpjZipmtbNu2bbrkpM/S6c+mp7bx8aWa/dT/PLklwsYnts+bLrQvVSaPDA1Sr1mv1zpYUvPOZ5Ah5bpH6CqTpzWeAO4EcMTMvlzb9QCAvdX3vQAOJcoghBgATz/7BwH8KYCfkHyq2vbXAL4I4D6S+wD8AsDNvUgohMiCpzX+3xE2RK7NK44Qoi+GHUFHZHDEhukOi5K4ZoY7Qwb3+OWYimpqrdtnNyTEF+oljOsWou/hnhmvzdi6Y4UQPSFlF6IQBp4IU7fj0xY9GI25nnRMtzXEUokt5GHOdKFjZiOceqVyHjMGE3+Ra4BnLFs1uxCFIGUXohAGNeOnG+NnVzlDcF+GggdjMaZ6Kt2tbl+k2mR7PCkU6hz7BqN51UJCZb+Cb6KaXYhCkLILUQhSdiEKYTzhn7bQe6f3Nem38BLt4SsTdqRz9K7Fopga6+0oecv1En9ifJJ0feq2joYJITohZReiEEZkxicwkr6tpJ6dvl+zo3cFwl2U09fTa3afzmU28G/7kbPuWHu6VHM//ix4wxan5d6GanYhCkHKLkQhSNmFKIRx+uwj8cXrxLrbBvPTc7yaY6OUR0JakO7Q8e1b5sHr28clmW1J2PyYvKhmF6IQpOxCFMLwZvzITPT4aLiEThe9PhPIYZ7nmNrW54JyaQsX1tcPZJJbcBo9mkIUgpRdiEIYZWt82irDftMqe8qOr8yFNpDXC/euHxITMJRflJQVKs4kYj09+fxe1exCFIIn1ttbSP6Q5I9IPkPyC9X2i0k+RvIoyXtJntu/uEKIVDw1+28AXGNm7wOwB8D1JK8E8CUAXzGzdwN4FcC+3qQUQnRmU2W3Cf9T/Tyn+hiAawDcX20/CODGPgScjRIc+mums9one/TcrKw3PqPEK+BUOqt9msT2pVC/w4b8+Y+N5tNu02G+WvDGZz+riuB6EsBDAH4O4DUze71KcgzAhYFj95NcJbm6trbmOg0hRH5cym5mb5jZHgA7AVwB4L3eAszsgJmtmNnK8vJympRCiM7M1fVmZq+RfBjABwCcR/LsqnbfCeC4Jw/vkgUueaLlZDDYU7qlBiSpl8ubYRZyO019h0wdO91cEk9r/DLJ86rvbwVwHYAjAB4GcFOVbC+AQ50kEUL0iqdm3wHgIMmzMHk53GdmD5J8FsA9JP8OwJMA7uxRTiFERzZVdjP7MYDLWra/gIn/non5Ta9BjbUeTfctMMW8B59hC5vaua9Fhvw8V3Mk3qcQom+k7EIUgpRdiEIYfNbbRufBFvbYspPb7esj/+JI8aNTG18SbpBFQ0C3o5pdiEKQsgtRCIOb8eEgPZsfMVay90o58a4h0at8W6LfMDOhc+zl3EOhq+ZHNbsQhSBlF6IQFrAGnSd65YJM95hJGnkthpKlLtWWNv9mwPb4EqqI3CZ5dndn/kkxJdw2IQSk7EIUg5RdiEIY0brxI+hiiznPiVmkpAvvS303L7V82yiro/NYQldbDrJfp/n1RTW7EIUgZReiEEZkxos2+n4bL2r037CMoFs3GnU1x/qLmggjhKiQsgtRCGWY8Ykj48aHd6xdE994vaXaPrdJP+hEGGv8qi9M7jWF4wuQdyNmqseIxS1u3zeb8+ZlbalHXQiRjpRdiEKQsgtRCGX47Gdsn5LvxOqj5LKMoHMf0m+XVzjHVN+5T7ztCOGwaBbx7T3hztw1exXJ9UmSD1a/Lyb5GMmjJO8lea43LyHE8Mxjxt+CSYy3Db4E4Ctm9m4ArwLYl1MwIURevPHZdwL4EwBfq34TwDUA7q+SHARwYw/y+VlK/AwoUspx67XPPISOW4/sS0vYBxb4sPGp7xsDTfnqhM7JGmfR3F/P3Wqf6T/PdfA+g18F8Hmcvu3vAvBaFa4ZAI4BuNCZlxBiAXhCNn8cwEkzeyKlAJL7Sa6SXF1bW0vJQgiRAU/N/kEAnyD5IoB7MDHf7wBwHsmN1vydAI63HWxmB8xsxcxWlpeXM4gshEhhU2U3s9vNbKeZ7QbwSQA/MLNPA3gYwE1Vsr0ADnURJMn7Gsj3TiXV7fX627FPZ5oNDkmZh/zXJmE/NS2dt6y+ibU3zJ9DzLf3nFEXNbkVwF+RPIqJD39nh7yEED0z16AaM3sEwCPV9xcAXJFfJCFEH4xmBJ3bsElbVF3MS/butrCRmT4PzRODIAd5F55opo0f1T7TLWWMoFREiEKQsgtRCKMx491sJdN9vWFsLdWMLa+ZnHqOofwHjBIVJ7TwxDx4j0tJl7LwRBoWXZSinq4bY1cXIUQmpOxCFIKUXYhC2Ho+u/f15F1/MeUYt2/b8MBSfOJYG0Vsn1deb7zpM3KB+c1G620QXlAiR1mM/PKW5Umlml2IQpCyC1EI4zHjc792cnQxZTddQ8aWs/tmntCvXlclh1vkovuKcV7jeQwrzs1HbGxcPlSzC1EIUnYhCmE8ZnwKfY+mSzJdreXbLL2bml3N7kHDOk2TYq73Ozs9Lff4eLx26fs8D9XsQhSClF2IQpCyC1EIw/vsOV8vKRGLU/NwE1uUYEHrmw/WvZZG6kyvPueyefOLET8vXy7+bkiFbBZCVEjZhSiErd31VifWVeSd1JG5u6lpqsUnPIyM7Itc+Neg63plcpj+dfow/VNGCXbtylXNLkQhSNmFKIRxmvE5RsZ5j+txnjazzIOOkHJtsk+E8Rqo/mvRZ5+Ft+V/yFb73OWGcCl7Feft1wDeAPC6ma2QvADAvQB2A3gRwM1m9mo/YgohujJP3fARM9tjZivV79sAHDazSwAcrn4LIUZKF5/9BgAHq+8HAdzYWRohRG94ld0AfJ/kEyT3V9u2m9mJ6vvLALZnl64L3hCnWUOfNkmMOjpkdFpvyNgpUiKhhq9FWnzTNEJRUYce25hS7vR1mv7z4G2gu8rMjpP8PQAPkfxpfaeZGclWuauXw34A2LVrl7M4IURuXHWHmR2v/p8E8G1More+QnIHAFT/TwaOPWBmK2a2sry8nEdqIcTcbKrsJN9G8h0b3wF8FMDTAB4AsLdKthfAoblKjpqJPbOocqeIGHJe+WLpQvuWnJ8oTcO7/gmd15DGeirt8jXN/T7Pwu9mTO/d+IvhMeO3A/g2yY30/2Rm3yX5OID7SO4D8AsANzvPRwixADZVdjN7AcD7Wrb/N4Br+xBKCJGfxY2gS51j3jWay2ZpF0KGaRLrEaPSfb7esVzhNdP8C0Znxin69MpvzalJ7Zk0o8zmOJPc6+d5WuQ1Nl6IQpCyC1EIUnYhCmFxPntKCKbUPEbno6cSmzkW8569vri3M8nrz1otXZgs3nxCP1hT9jp9z0TrHgc21t7Qjmp2IQpByi5EIYyz621hUVZTyR3yaUFLTk/hk8HrPCzyjOrdUnHzvO52DBOSKZ35uwNVswtRCFJ2IQpheDN+w9yOjWpLGUE3Evym+vzt07MjvlLo7mg05Qjl75Uv94g0f7pxGugpaClpIcSbSNmFKAQpuxCFMP4RdH3nkUTfvl67BzY7Sirv2C6b8rfDo/U8o7Wmj4iTvpa7d+5Yt/FwPa/+Pxiq2YUoBCm7EIVw5oZ/6hWvYRfu6AktlDBfuV5SOsG8XXRpE3CmR6j5FpGIjRqLdUqa2wVpL2s8Znt4ApKHUaqSECI/UnYhCkHKLkQhLMBn3/A1nH5k6iIXPS6yOItvgciU2Vf5l04In4fXE4+HW27fFz8Ln0zz5ZmCzw/Ov1hkmFArRUq5qtmFKAQpuxCFsMCut8yjwZJH03Xv9vJ2AYXxGmWp16y7sZkyGi51tfVwF2UsZXh7wir8UYacpZcTV81O8jyS95P8KckjJD9A8gKSD5F8vvp/ft/CCiHS8ZrxdwD4rpm9F5NQUEcA3AbgsJldAuBw9VsIMVI2NeNJvhPAhwH8GQCY2W8B/JbkDQCurpIdBPAIgFs3y29jtNSsedbVOFpcZNDYODkE9qVJO8+UDO9CFN1K8raWzyNpaBzfkIthLIo+ZffU7BcDWAPwjySfJPm1KnTzdjM7UaV5GZNor0KIkeJR9rMBXA7gH8zsMgD/i4bJbmbtIaQBkNxPcpXk6traWld5hRCJeJT9GIBjZvZY9ft+TJT/FZI7AKD6f7LtYDM7YGYrZrayvLycQ2YhRAKbKruZvQzgJZLvqTZdC+BZAA8A2Ftt2wvgUC8Sbgms9sl9hEU+jHzaS4jl4E0XOqYPQmfU1uLjuSqhvHOcS2p+8WchkGPokYjg7Wf/SwB3kzwXwAsA/hyTF8V9JPcB+AWAm515CSEWgEvZzewpACstu67NKo0QojcWNhHG3xWzlVcAyyvr7Pi58MSIrquzpYxbm4taJhaxeRczJWiI/HwLUaTcnxAaGy9EIUjZhSiEwc34DVMkbVrEPOl6bCuemTufe6rFYvCN/fMTnacd2RkyV713eFFXvbn8dmhu/8be2W9teQbSJdwg1exCFIKUXYhCkLILUQiD++zzzp4a0BOPv/rWA99n6Le7rQRSW2kWwXT7QnjRDO8cz6gr3rEfUjW7EIUgZReiEDiZnTpQYeQaJlNkTw1WaJhtWLwcY5ABGIccY5ABGIccXWT4fTNrnV46qLIDAMlVM2sbZ1+cHGOQYSxyjEGGscjRlwwy44UoBCm7EIWwCGU/sIAy2xiDHGOQARiHHGOQARiHHL3IMLjPLoRYDDLjhSiEQZWd5PUknyN5lORgQSVI3kXyJMmna9sGjWhD8iKSD5N8luQzJG8ZWg6SbyH5Q5I/qmT4QrX9YpKPVffl3mr5sV4heVa1NPmDC5ThRZI/IfkUydVq2+CRjoaKuDSYspM8C8DfA/hjAJcC+BTJSwcq/usArm9sGzqizesAPmdmlwK4EsBnqvMfUo7fALjGzN4HYA+A60leCeBLAL5iZu8G8CqAfT3KsMEtmEQW2mARMgDAR8xsT62raxGRjoaJuGRmg3wAfADA92q/bwdw+4Dl7wbwdO33cwB2VN93AHhuKFmqMg8BuG5RcgD4XQD/CeD9mAzgOLvtPvVU9s7qAb4GwIOYjPQeVIaqnBcBbGtsG/R+AHgngP9C1X7WpxxDmvEXAnip9vtYtW1RLCyiDcndAC4D8NjQclTm81OYrPP/EICfA3jNzF6vkgxxX74K4PM4PaXoXQuQAZhMLfk+ySdI7q+2Df1cDBZxSQ10iEe0yQ3JtwP4JoDPmtmvhpbDzN4wsz2Y1K5XAHhvn+U1IflxACfN7Ikhyw1wlZldjolr+RmSH67vHOi56BRxaR6GVPbjAC6q/d5ZbVsUrog2OSF5DiaKfreZfWtRcgCAmb0G4GFMTObzSG5Md+77vnwQwCdIvgjgHkxM+TsGlgEAYGbHq/8nAXwbk5ff0PejU8SleRhS2R8HcEnV6nougE9iElVmUQwa0YYkAdwJ4IiZfXkRcpBcJnle9f2tmLQZHMFE6W8aQgYzu93MdprZbkyegR+Y2aeHlAEASL6N5Ds2vgP4KICnMfBzYUNGXOq7EaTR6PAxAD/DxE/8mwHL/QaAEwD+D5M36T5M/MTDAJ4H8K8ALuhZhqswMcV+DOCp6vOxIeUA8IcAnqxkeBrA31bb/wDADwEcBfDPAH5noPtyNYAHFyFDVd6Pqs8zG8/j0M9FVeYeAKvVffkXAOf3IYdG0AlRCGqgE6IQpOxCFIKUXYhCkLILUQhSdiEKQcouRCFI2YUoBCm7EIXw//8kfYvYVPWVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = get_img_from_example(parsed_examples[13])\n",
    "print(img)\n",
    "plt.imshow(img)\n",
    "print(img.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8400864917552724"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffb4164c0a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsed_examples[16]\n",
    "img, label = get_img_from_example(parsed_examples[16])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.048751380743994"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(20, 30), dpi= 80, facecolor='w', edgecolor='k')\n",
    "for i in range(12,13):\n",
    "    plt.subplot(5, 5, i)\n",
    "    img, label = get_img_from_example(parsed_examples[i])\n",
    "    plt.imshow(img).axes.get_xaxis().set_visible(False)\n",
    "    plt.imshow(img).axes.get_yaxis().set_visible(False)\n",
    "    plt.title(str(label))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirlist = lambda di: [os.path.join(di, file) for file in os.listdir(di) if 'part-' in file]\n",
    "training_files = dirlist('data/val/')\n",
    "\n",
    "def parse_visual(data):\n",
    "    dataset = tf.data.TFRecordDataset(data)\n",
    "    # pattern for one part file\n",
    "    # dataset = tf.data.TFRecordDataset('part-r-00099')\n",
    "    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "\n",
    "    features = {\n",
    "        'B2': tf.io.FixedLenFeature([], tf.string),\n",
    "        'B3': tf.io.FixedLenFeature([], tf.string),\n",
    "        'B4': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    parsed_examples = [tf.io.parse_single_example(data, features) for data in iterator]\n",
    "    return parsed_examples\n",
    "\n",
    "parsed_examples = parse_visual(training_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_from_example(parsed_example, intensify=True):\n",
    "    rgbArray = np.zeros((65,65,3), 'uint8')\n",
    "    for i, band in enumerate(['B4', 'B3', 'B2']):\n",
    "        band_data = np.frombuffer(parsed_example[band].numpy(), dtype=np.uint8)\n",
    "        band_data = band_data.reshape(65, 65)\n",
    "        if intensify:\n",
    "            band_data = band_data/np.max(band_data)*255\n",
    "        else:\n",
    "            band_data = band_data*255\n",
    "        rgbArray[..., i] = band_data\n",
    "        \n",
    "    label = tf.cast(parsed_example['label'], tf.int32).numpy()\n",
    "        \n",
    "    return rgbArray, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20, 30), dpi= 80, facecolor='w', edgecolor='k')\n",
    "for i in range(1,26):\n",
    "    plt.subplot(5, 5, i)\n",
    "    img, label = get_img_from_example(parsed_examples[i])\n",
    "    plt.imshow(img).axes.get_xaxis().set_visible(False)\n",
    "    plt.imshow(img).axes.get_yaxis().set_visible(False)\n",
    "    plt.title(str(label))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list_from_folder(folder, data_path):\n",
    "  folderpath = os.path.join(data_path, folder)\n",
    "  filelist = []\n",
    "  for filename in os.listdir(folderpath):\n",
    "    if filename.startswith('part-') and not filename.endswith('gstmp'):\n",
    "      filelist.append(os.path.join(folderpath, filename))\n",
    "  return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = file_list_from_folder(\"train\", \"data/\")\n",
    "val = file_list_from_folder(\"val\", 'data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "  'B1': tf.io.FixedLenFeature([], tf.string),\n",
    "  'B2': tf.io.FixedLenFeature([], tf.string),\n",
    "  'B3': tf.io.FixedLenFeature([], tf.string),\n",
    "  'B4': tf.io.FixedLenFeature([], tf.string),\n",
    "  'B5': tf.io.FixedLenFeature([], tf.string),\n",
    "  'B6': tf.io.FixedLenFeature([], tf.string),\n",
    "  'B7': tf.io.FixedLenFeature([], tf.string),\n",
    "  'B8': tf.io.FixedLenFeature([], tf.string),\n",
    "  'B9': tf.io.FixedLenFeature([], tf.string),\n",
    "  'B10': tf.io.FixedLenFeature([], tf.string),\n",
    "  'B11': tf.io.FixedLenFeature([], tf.string),\n",
    "  'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecords(filelist, batch_size, buffer_size, include_viz=False):\n",
    "  # try a subset of possible bands\n",
    "  def _parse_(serialized_example, keylist=['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8']):\n",
    "    example = tf.io.parse_single_example(serialized_example, features)\n",
    "    \n",
    "    def getband(example_key):\n",
    "      img = tf.io.decode_raw(example_key, tf.uint8)\n",
    "      return tf.reshape(img[:IMG_DIM**2], shape=(IMG_DIM, IMG_DIM, 1))\n",
    "    \n",
    "    bandlist = [getband(example[key]) for key in keylist]\n",
    "    # combine bands into tensor\n",
    "    image = tf.concat(bandlist, -1)\n",
    "\n",
    "    # one-hot encode ground truth labels \n",
    "    label = tf.cast(example['label'], tf.int32)\n",
    "    label = tf.one_hot(label, NUM_CLASSES)\n",
    "   \n",
    "    # if logging RGB images as examples, generate RGB image from 11-channel satellite image\n",
    "    if include_viz:\n",
    "      image = get_img_from_example(example)\n",
    "      return {'image' : image, 'label': example['label']}, label\n",
    "    return {'image': image}, label\n",
    "    \n",
    "  tfrecord_dataset = tf.data.TFRecordDataset(filelist) \n",
    "  tfrecord_dataset = tfrecord_dataset.map(lambda x:_parse_(x)).shuffle(buffer_size).repeat(-1).batch(batch_size)\n",
    "  tfrecord_iterator = tfrecord_dataset.make_one_shot_iterator()\n",
    "  image, label = tfrecord_iterator.get_next()\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 16000\n",
    "NUM_VAL = 3200\n",
    "IMG_DIM = 65\n",
    "NUM_CLASSES = 4\n",
    "TOTAL_TRAIN = 40000\n",
    "TOTAL_VAL = 10778\n",
    "TOTAL_TRAIN2 = 86317\n",
    "TOTAL_VAL2 = 10778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "  train = file_list_from_folder(\"train\", data_path)\n",
    "  val = file_list_from_folder(\"val\", data_path)\n",
    "  return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecords, val_tfrecords = load_data(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = parse_tfrecords(train_tfrecords, TOTAL_TRAIN, TOTAL_TRAIN)\n",
    "val_images, val_labels = parse_tfrecords(val_tfrecords, TOTAL_VAL, TOTAL_VAL)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model4():\n",
    "    from tensorflow.keras import layers, initializers\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(65, 65, 7), name='image'))\n",
    "    model.add(layers.Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(64, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(layers.Conv2D(64, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(layers.Conv2D(filters=128, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(4, activation='softmax'))\n",
    "    # set up optimizer\n",
    "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label='train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n",
    "    ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
    "    ax2.set_ylim(0.25, 1.)\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "To easily improve the accuracy of a model without much work, we can generate new data: the data augmentation. This widely used technique consists in applying little transformation to input images without changing its label, as mirroring, cropping, intensity changes, etc. The improved performance simply results from the Neural network training with more different data.\n",
    "\n",
    "The natural way to generate these new images is to apply some transformations and train the model on the original and new images. However, such procedure requires to keep all these images in memory : it can be very intensive, to the point that your computer memory cannot hold any new image (your computer might even crash).\n",
    "\n",
    "For this reason, we will augment the data on the fly, meaning that we will create new data, use them to fit the model, then delete them. Here, Keras is our friend as it provides the utils to do all this job for us. Look at the following code : the general writing can seem odd but don't be panicked: just look at the function arguments that defines the augmentation techniques that we will use and that you can check in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data generator\n",
    "X_tr = train_images[\"image\"][:30000]\n",
    "y_tr = train_labels[:30000]\n",
    "X_val = train_images[\"image\"][30000:]\n",
    "y_val = train_labels[30000:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.where([i[i.std() >= 10].all() for i in X_tr.numpy()])\n",
    "X_tr, y_tr = X_tr.numpy(), y_tr.numpy()\n",
    "X_tr, y_tr = X_tr[indices], y_tr[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.where([i[i.std() >= 10].all() for i in X_val.numpy()])\n",
    "X_val, y_val = X_val.numpy(), y_val.numpy()\n",
    "X_val, y_val = X_val[indices], y_val[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=False,\n",
    "#     featurewise_std_normalization=False,\n",
    "#     rotation_range=10,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True,\n",
    "#     zoom_range=(0.8, 1.2),) \n",
    "\n",
    "# datagen.fit(train_images[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "503/936 [===============>..............] - ETA: 50s - loss: 1.0455 - accuracy: 0.6103"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-70f1e32cbc40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#                         callbacks=[es],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#                         validation_data=(X_val, y_val), batch_size = 32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m history_2 = model.fit(X_tr,y_tr, \n\u001b[0m\u001b[1;32m     15\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/lewagon/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The model\n",
    "#train_flow = datagen.flow(X_tr, y_tr, batch_size=32)\n",
    "model = initialize_model4()\n",
    "model = compile_model(model)\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# The early stopping criterion\n",
    "es = EarlyStopping(patience=20, restore_best_weights = True, verbose = 1)\n",
    "\n",
    "# The fit\n",
    "# history_2 = model.fit(train_flow, \n",
    "#                         epochs=1000, \n",
    "#                         callbacks=[es], \n",
    "#                         validation_data=(X_val, y_val), batch_size = 32)\n",
    "history_2 = model.fit(X_tr,y_tr, \n",
    "                        epochs=1000, \n",
    "                        callbacks=[es], \n",
    "                        validation_data=(X_val, y_val), batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10778, 65, 65, 7)\n",
      "(10753, 65, 65, 7)\n"
     ]
    }
   ],
   "source": [
    "X_test = val_images[\"image\"].numpy()\n",
    "print(X_test.shape)\n",
    "y_test = val_labels.numpy()\n",
    "indices = np.where([i[i.std() >= 10].all() for i in X_test])\n",
    "X_test, y_test = X_test[indices], y_test[indices]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_history(history_2)\n",
    "plt.show()\n",
    "res = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(f'The accuracy is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trrgb = X_tr[:,:,:,2:5]\n",
    "X_trrgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "def load_model():\n",
    "    model = VGG16(weights=\"imagenet\", include_top=False, input_shape=X_trrgb[0].shape)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        928       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 31, 64)        8256      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 128)       32896     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 128)       65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 423,588\n",
      "Trainable params: 0\n",
      "Non-trainable params: 423,588\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def set_nontrainable_layers(model):\n",
    "    # Set the first layers to be untrainable\n",
    "    model.trainable = False\n",
    "    \n",
    "    return model\n",
    "\n",
    "model2 = set_nontrainable_layers(model)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def add_last_layers(model):\n",
    "    base_model = set_nontrainable_layers(model)\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer = layers.Dense(500, activation='relu')\n",
    "    prediction_layer = layers.Dense(4, activation='softmax')\n",
    "    \n",
    "    \n",
    "    model = models.Sequential([\n",
    "        model,\n",
    "        flatten_layer,\n",
    "        dense_layer,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = add_last_layers(model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    \n",
    "    opt = optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    model = load_model()\n",
    "    model = add_last_layers(model)\n",
    "    model = compile_model(model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model2 = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "X_trrgb = X_tr[:,:,:,2:5]\n",
    "X_valrgb = X_val[:,:,:,2:5]\n",
    "X_testrgb = X_test[:,:,:,2:5]\n",
    "X_train = preprocess_input(X_trrgb) \n",
    "X_val = preprocess_input(X_valrgb)\n",
    "X_test = preprocess_input(X_testrgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=20, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history = model2.fit(X_train, y_tr, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=1000, \n",
    "                    batch_size=32, \n",
    "                    callbacks=[es],verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model2.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(f'The accuracy is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-44-98e1cbd73a71>:23: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/1000\n",
      "1872/1872 [==============================] - 560s 299ms/step - loss: 2.4477 - accuracy: 0.5214 - val_loss: 1.7348 - val_accuracy: 0.5797\n",
      "Epoch 2/1000\n",
      "1872/1872 [==============================] - 577s 308ms/step - loss: 1.4332 - accuracy: 0.5588 - val_loss: 1.2388 - val_accuracy: 0.5941\n",
      "Epoch 3/1000\n",
      "1872/1872 [==============================] - 568s 304ms/step - loss: 1.1204 - accuracy: 0.5917 - val_loss: 1.0783 - val_accuracy: 0.5955\n",
      "Epoch 4/1000\n",
      "1872/1872 [==============================] - 585s 313ms/step - loss: 1.0101 - accuracy: 0.6150 - val_loss: 0.9883 - val_accuracy: 0.6194\n",
      "Epoch 5/1000\n",
      "1872/1872 [==============================] - 611s 327ms/step - loss: 0.9654 - accuracy: 0.6307 - val_loss: 0.9687 - val_accuracy: 0.6361\n",
      "Epoch 6/1000\n",
      "1872/1872 [==============================] - 671s 358ms/step - loss: 0.9484 - accuracy: 0.6356 - val_loss: 0.9517 - val_accuracy: 0.6391\n",
      "Epoch 7/1000\n",
      "1872/1872 [==============================] - 652s 348ms/step - loss: 0.9319 - accuracy: 0.6413 - val_loss: 0.9395 - val_accuracy: 0.6389\n",
      "Epoch 8/1000\n",
      "1872/1872 [==============================] - 664s 354ms/step - loss: 0.9211 - accuracy: 0.6444 - val_loss: 0.9282 - val_accuracy: 0.6469\n",
      "Epoch 9/1000\n",
      "1872/1872 [==============================] - 679s 363ms/step - loss: 0.9139 - accuracy: 0.6473 - val_loss: 0.9216 - val_accuracy: 0.6446\n",
      "Epoch 10/1000\n",
      "1872/1872 [==============================] - 640s 342ms/step - loss: 0.9025 - accuracy: 0.6524 - val_loss: 0.9139 - val_accuracy: 0.6517\n",
      "Epoch 11/1000\n",
      "1872/1872 [==============================] - 661s 353ms/step - loss: 0.8994 - accuracy: 0.6556 - val_loss: 0.9201 - val_accuracy: 0.6476\n",
      "Epoch 12/1000\n",
      "1872/1872 [==============================] - 652s 348ms/step - loss: 0.8902 - accuracy: 0.6562 - val_loss: 0.8980 - val_accuracy: 0.6578\n",
      "Epoch 13/1000\n",
      "1872/1872 [==============================] - 755s 403ms/step - loss: 0.8852 - accuracy: 0.6582 - val_loss: 0.9012 - val_accuracy: 0.6548\n",
      "Epoch 14/1000\n",
      "1872/1872 [==============================] - 688s 367ms/step - loss: 0.8784 - accuracy: 0.6627 - val_loss: 0.8983 - val_accuracy: 0.6558\n",
      "Epoch 15/1000\n",
      "1872/1872 [==============================] - 659s 352ms/step - loss: 0.8678 - accuracy: 0.6631 - val_loss: 0.8971 - val_accuracy: 0.6579\n",
      "Epoch 16/1000\n",
      "1872/1872 [==============================] - 699s 373ms/step - loss: 0.8686 - accuracy: 0.6644 - val_loss: 0.8962 - val_accuracy: 0.6595\n",
      "Epoch 17/1000\n",
      "1872/1872 [==============================] - 681s 364ms/step - loss: 0.8647 - accuracy: 0.6648 - val_loss: 0.8933 - val_accuracy: 0.6565\n",
      "Epoch 18/1000\n",
      "1872/1872 [==============================] - 657s 351ms/step - loss: 0.8642 - accuracy: 0.6650 - val_loss: 0.8885 - val_accuracy: 0.6621\n",
      "Epoch 19/1000\n",
      "1872/1872 [==============================] - 651s 348ms/step - loss: 0.8585 - accuracy: 0.6671 - val_loss: 0.8841 - val_accuracy: 0.6611\n",
      "Epoch 20/1000\n",
      "1872/1872 [==============================] - 686s 366ms/step - loss: 0.8527 - accuracy: 0.6720 - val_loss: 0.8713 - val_accuracy: 0.6653\n",
      "Epoch 21/1000\n",
      "1872/1872 [==============================] - 678s 362ms/step - loss: 0.8498 - accuracy: 0.6705 - val_loss: 0.8746 - val_accuracy: 0.6629\n",
      "Epoch 22/1000\n",
      "1872/1872 [==============================] - 693s 370ms/step - loss: 0.8501 - accuracy: 0.6743 - val_loss: 0.8783 - val_accuracy: 0.6668\n",
      "Epoch 23/1000\n",
      "1872/1872 [==============================] - 731s 390ms/step - loss: 0.8517 - accuracy: 0.6706 - val_loss: 0.8705 - val_accuracy: 0.6683\n",
      "Epoch 24/1000\n",
      "1872/1872 [==============================] - 740s 395ms/step - loss: 0.8442 - accuracy: 0.6739 - val_loss: 0.8752 - val_accuracy: 0.6683\n",
      "Epoch 25/1000\n",
      "1872/1872 [==============================] - 686s 366ms/step - loss: 0.8379 - accuracy: 0.6767 - val_loss: 0.8730 - val_accuracy: 0.6678\n",
      "Epoch 26/1000\n",
      "1872/1872 [==============================] - 764s 408ms/step - loss: 0.8397 - accuracy: 0.6741 - val_loss: 0.8625 - val_accuracy: 0.6692\n",
      "Epoch 27/1000\n",
      "1872/1872 [==============================] - 793s 423ms/step - loss: 0.8352 - accuracy: 0.6737 - val_loss: 0.8760 - val_accuracy: 0.6686\n",
      "Epoch 28/1000\n",
      "1872/1872 [==============================] - 724s 387ms/step - loss: 0.8333 - accuracy: 0.6804 - val_loss: 0.8661 - val_accuracy: 0.6711\n",
      "Epoch 29/1000\n",
      "1872/1872 [==============================] - 802s 428ms/step - loss: 0.8281 - accuracy: 0.6804 - val_loss: 0.8492 - val_accuracy: 0.6692\n",
      "Epoch 30/1000\n",
      "1872/1872 [==============================] - 907s 485ms/step - loss: 0.8302 - accuracy: 0.6805 - val_loss: 0.8663 - val_accuracy: 0.6711\n",
      "Epoch 31/1000\n",
      "1872/1872 [==============================] - 852s 455ms/step - loss: 0.8270 - accuracy: 0.6806 - val_loss: 0.8613 - val_accuracy: 0.6693\n",
      "Epoch 32/1000\n",
      "1872/1872 [==============================] - 748s 400ms/step - loss: 0.8240 - accuracy: 0.6822 - val_loss: 0.8599 - val_accuracy: 0.6739\n",
      "Epoch 33/1000\n",
      "1872/1872 [==============================] - 699s 373ms/step - loss: 0.8205 - accuracy: 0.6835 - val_loss: 0.8619 - val_accuracy: 0.6748\n",
      "Epoch 34/1000\n",
      "1872/1872 [==============================] - 728s 389ms/step - loss: 0.8203 - accuracy: 0.6834 - val_loss: 0.8578 - val_accuracy: 0.6774\n",
      "Epoch 35/1000\n",
      "1872/1872 [==============================] - 719s 384ms/step - loss: 0.8197 - accuracy: 0.6817 - val_loss: 0.8655 - val_accuracy: 0.6688\n",
      "Epoch 36/1000\n",
      "1872/1872 [==============================] - 759s 405ms/step - loss: 0.8203 - accuracy: 0.6850 - val_loss: 0.8552 - val_accuracy: 0.6799\n",
      "Epoch 37/1000\n",
      "1872/1872 [==============================] - 742s 396ms/step - loss: 0.8152 - accuracy: 0.6860 - val_loss: 0.8555 - val_accuracy: 0.6762\n",
      "Epoch 38/1000\n",
      "1872/1872 [==============================] - 657s 351ms/step - loss: 0.8147 - accuracy: 0.6852 - val_loss: 0.8453 - val_accuracy: 0.6765\n",
      "Epoch 39/1000\n",
      "1872/1872 [==============================] - 635s 339ms/step - loss: 0.8136 - accuracy: 0.6863 - val_loss: 0.8479 - val_accuracy: 0.6780\n",
      "Epoch 40/1000\n",
      "1872/1872 [==============================] - 637s 340ms/step - loss: 0.8114 - accuracy: 0.6875 - val_loss: 0.8506 - val_accuracy: 0.6789\n",
      "Epoch 41/1000\n",
      "1872/1872 [==============================] - 632s 338ms/step - loss: 0.8123 - accuracy: 0.6892 - val_loss: 0.8427 - val_accuracy: 0.6811\n",
      "Epoch 42/1000\n",
      "1872/1872 [==============================] - 637s 340ms/step - loss: 0.8082 - accuracy: 0.6880 - val_loss: 0.8471 - val_accuracy: 0.6774\n",
      "Epoch 43/1000\n",
      "1872/1872 [==============================] - 643s 344ms/step - loss: 0.8066 - accuracy: 0.6904 - val_loss: 0.8489 - val_accuracy: 0.6752\n",
      "Epoch 44/1000\n",
      "1872/1872 [==============================] - 675s 360ms/step - loss: 0.8054 - accuracy: 0.6874 - val_loss: 0.8404 - val_accuracy: 0.6772\n",
      "Epoch 45/1000\n",
      "1872/1872 [==============================] - 607s 325ms/step - loss: 0.8063 - accuracy: 0.6865 - val_loss: 0.8532 - val_accuracy: 0.6746\n",
      "Epoch 46/1000\n",
      "1872/1872 [==============================] - 566s 302ms/step - loss: 0.8061 - accuracy: 0.6871 - val_loss: 0.8514 - val_accuracy: 0.6780\n",
      "Epoch 47/1000\n",
      "1872/1872 [==============================] - 578s 309ms/step - loss: 0.7986 - accuracy: 0.6906 - val_loss: 0.8381 - val_accuracy: 0.6818\n",
      "Epoch 48/1000\n",
      "1872/1872 [==============================] - 583s 312ms/step - loss: 0.8024 - accuracy: 0.6898 - val_loss: 0.8490 - val_accuracy: 0.6824\n",
      "Epoch 49/1000\n",
      "1872/1872 [==============================] - 592s 316ms/step - loss: 0.7987 - accuracy: 0.6918 - val_loss: 0.8309 - val_accuracy: 0.6830\n",
      "Epoch 50/1000\n",
      "1872/1872 [==============================] - 668s 357ms/step - loss: 0.7979 - accuracy: 0.6933 - val_loss: 0.8421 - val_accuracy: 0.6812\n",
      "Epoch 51/1000\n",
      "1872/1872 [==============================] - 658s 351ms/step - loss: 0.7972 - accuracy: 0.6908 - val_loss: 0.8420 - val_accuracy: 0.6811\n",
      "Epoch 52/1000\n",
      "1872/1872 [==============================] - 686s 366ms/step - loss: 0.7975 - accuracy: 0.6917 - val_loss: 0.8482 - val_accuracy: 0.6789\n",
      "Epoch 53/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1872/1872 [==============================] - 685s 366ms/step - loss: 0.7998 - accuracy: 0.6922 - val_loss: 0.8395 - val_accuracy: 0.6809\n",
      "Epoch 54/1000\n",
      "1872/1872 [==============================] - 683s 365ms/step - loss: 0.7909 - accuracy: 0.6948 - val_loss: 0.8450 - val_accuracy: 0.6828\n",
      "Epoch 55/1000\n",
      "1872/1872 [==============================] - 683s 365ms/step - loss: 0.7943 - accuracy: 0.6920 - val_loss: 0.8264 - val_accuracy: 0.6848\n",
      "Epoch 56/1000\n",
      "1872/1872 [==============================] - 669s 357ms/step - loss: 0.7927 - accuracy: 0.6944 - val_loss: 0.8349 - val_accuracy: 0.6865\n",
      "Epoch 57/1000\n",
      "1872/1872 [==============================] - 746s 398ms/step - loss: 0.7888 - accuracy: 0.6958 - val_loss: 0.8407 - val_accuracy: 0.6833\n",
      "Epoch 58/1000\n",
      "1872/1872 [==============================] - 787s 421ms/step - loss: 0.7853 - accuracy: 0.6962 - val_loss: 0.8376 - val_accuracy: 0.6879\n",
      "Epoch 59/1000\n",
      "1872/1872 [==============================] - 777s 415ms/step - loss: 0.7922 - accuracy: 0.6935 - val_loss: 0.8285 - val_accuracy: 0.6877\n",
      "Epoch 60/1000\n",
      "1872/1872 [==============================] - 759s 406ms/step - loss: 0.7931 - accuracy: 0.6945 - val_loss: 0.8373 - val_accuracy: 0.6857\n",
      "Epoch 61/1000\n",
      "1872/1872 [==============================] - 700s 374ms/step - loss: 0.7864 - accuracy: 0.6969 - val_loss: 0.8354 - val_accuracy: 0.6867\n",
      "Epoch 62/1000\n",
      "1872/1872 [==============================] - 762s 407ms/step - loss: 0.7922 - accuracy: 0.6925 - val_loss: 0.8389 - val_accuracy: 0.6815\n",
      "Epoch 63/1000\n",
      "1872/1872 [==============================] - 777s 415ms/step - loss: 0.7869 - accuracy: 0.6956 - val_loss: 0.8417 - val_accuracy: 0.6784\n",
      "Epoch 64/1000\n",
      "1872/1872 [==============================] - 760s 406ms/step - loss: 0.7794 - accuracy: 0.6983 - val_loss: 0.8458 - val_accuracy: 0.6837\n",
      "Epoch 65/1000\n",
      " 111/1872 [>.............................] - ETA: 8:58 - loss: 0.7337 - accuracy: 0.7241"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.5, 1.),\n",
    "    zoom_range=(0.5, 1.2))\n",
    "\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_trrgb)\n",
    "\n",
    "model_data_aug = build_model()\n",
    "\n",
    "train_flow = datagen.flow(X_trrgb, y_tr, batch_size=16)\n",
    "val_flow = datagen.flow(X_valrgb, y_val, batch_size=16)\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=20, verbose=1, restore_best_weights=True)\n",
    "history_data_aug = model_data_aug.fit_generator(train_flow, epochs=1000, validation_data=val_flow, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model_data_aug.evaluate(X_testrgb, y_test, verbose=1)\n",
    "\n",
    "print(f'The accuracy is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_data_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model_data_aug.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model_data_aug.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_testrgb, y_test, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "418.391px",
    "left": "1314.19px",
    "right": "20px",
    "top": "235px",
    "width": "482px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
